{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993eac84",
   "metadata": {},
   "source": [
    "## Improving transcription time by 50% through parellel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f8997",
   "metadata": {},
   "source": [
    "I was working on a notebook for transcribing videos.  \n",
    "I ecountered a problem when I wanted to transcribe hours of videos and it taking a long time.  \n",
    "By using parallel processing I was able to improve total speed of transcription by 50%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d40d55",
   "metadata": {},
   "source": [
    "This notebook takes youtube videos (from a database created in a sperate project) and transcribed all the videos listed. This notebook is a comparison of different methods to try and improve speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2bc444",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54055a8-4452-4440-895f-cf0f01569d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c9cc917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv # add this line\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3846224",
   "metadata": {},
   "source": [
    "#### whisper model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a211e4-0f71-483c-8f4c-312763cfb81e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import whisper\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3b1cd",
   "metadata": {},
   "source": [
    "#### google client set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31a1644-d2cf-46e3-a321-48372c281596",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = os.getenv('GOOGLE_DEVELOPER_KEY')\n",
    "\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey = DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4080e0",
   "metadata": {},
   "source": [
    "#### firebase set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7967c5d2-bb92-4004-901e-410e248f0f6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "# Use a service account.\n",
    "cred = credentials.Certificate('{}.json'.format(os.getenv('PROJECT_ID')))\n",
    "\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "db = firestore.client(app)\n",
    "batch = db.batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217213e",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab419409",
   "metadata": {},
   "source": [
    "#### functions calling to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5882bc6-1b5d-4a2a-a9d2-7bb3c919947d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_videos_for_channel_from_db(channelId):\n",
    "    \"\"\"\n",
    "    Retrieve list of videos from firebase\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.collection(u\"videos\").order_by('publishedAt', direction=firestore.Query.DESCENDING).where(u\"channelId\",u\"==\",u\"{}\".format(channelId)).stream()\n",
    "\n",
    "    collection = []\n",
    "    for doc in docs:\n",
    "        vid =doc.to_dict()\n",
    "        collection.append(vid)\n",
    "    return collection\n",
    "\n",
    "def get_all_transcripts_for_channel_from_db(channelId):\n",
    "    \"\"\"\n",
    "    Retrieve list of videos from firebase\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.collection(u\"WhisperTranscriptions\").where(u\"channelId\",u\"==\",u\"{}\".format(channelId)).stream()\n",
    "\n",
    "    collection = []\n",
    "    for doc in docs:\n",
    "        transcript =doc.to_dict()\n",
    "        collection.append(transcript)\n",
    "        \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce4668",
   "metadata": {},
   "source": [
    "#### functions for extracting details from response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beff51e9-775a-477b-9c7f-8c40c263ddc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getYoutubeDuration(videoId):\n",
    "    responseVideoDetails = youtube.videos().list( part=\"contentDetails\",id=videoId).execute()\n",
    "    durationResponse=responseVideoDetails['items'][0]['contentDetails']['duration']\n",
    "\n",
    "    duration_string = durationResponse.replace('PT',\"\")\n",
    "    number_values = re.findall('\\d+',duration_string)\n",
    "    symbols_available= ''.join([i for i in duration_string if not i.isdigit()])\n",
    "    symbol_map = {}\n",
    "    for symbol in 'HMS':\n",
    "        index = symbols_available.find(symbol)\n",
    "        if index > -1:\n",
    "            symbol_map[symbol] = number_values[index]\n",
    "\n",
    "    duration = 0\n",
    "\n",
    "\n",
    "    for idx in symbol_map:\n",
    "        if idx == \"H\":\n",
    "            duration = int(symbol_map[idx])*60*60 + duration\n",
    "        if idx == \"M\":\n",
    "            duration = int(symbol_map[idx])*60 + duration\n",
    "        if idx == \"S\":\n",
    "            duration = int(symbol_map[idx]) + duration\n",
    "\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0bafc",
   "metadata": {},
   "source": [
    "#### transcription functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3fd2cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_audio(url,_id):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        out_file=video.download(output_path=\"audio_files\")\n",
    "        base, ext = os.path.splitext(out_file)\n",
    "        new_file = 'audio_files/'+_id+'.mp3'\n",
    "        os.rename(out_file, new_file)\n",
    "        a = new_file\n",
    "    except Exception as e: # work on python 3.x\n",
    "        print('Could not download data for {}: '.format(_id),e)\n",
    "        return None\n",
    "    return a\n",
    "\n",
    "def transcribe_youtube_video(videoId, videoUrl,model):\n",
    "\n",
    "    result = {}\n",
    "\n",
    "# try:\n",
    "    start_time = time.time()\n",
    "\n",
    "    audio_downloaded = get_audio(videoUrl,videoId)\n",
    "    if not audio_downloaded:\n",
    "        print('Could not get transcription data {} Audio could not download.'.format(videoId))\n",
    "        return\n",
    "\n",
    "    print('Downloaded {}'.format(videoId))\n",
    "\n",
    "    # transcribe to get speech-to-text data\n",
    "    result = model.transcribe('audio_files/{}.mp3'.format(videoId))\n",
    "#     os.remove(\"audio_files/{}.mp3\".format(videoId))\n",
    "    source = \"whisper\"\n",
    "    time_to_transcbribe = time.time() - start_time\n",
    "    print('Transcribed {} in {}'.format(videoId,time_to_transcbribe))\n",
    "\n",
    "#     except Exception as e: # work on python 3.x\n",
    "#         print('Could not get transcription data {}.'.format(videoId),e)\n",
    "\n",
    "    return result\n",
    "\n",
    "def transcription_response_to_json(transcriptResponse, videoId, channelId):\n",
    "    transcriptObject = {}\n",
    "    transcriptObject['videoId'] = videoId\n",
    "    transcriptObject['channelId'] = channelId\n",
    "\n",
    "    transcriptObject['text'] = transcriptResponse['text']\n",
    "    segments = transcriptResponse['segments']\n",
    "    keys = ['start','end','text','id','seek']\n",
    "    transcriptObject['sentences'] = [{ keep: item[keep] for keep in keys } for item,i in zip(segments,range(len(segments)) )]\n",
    "    \n",
    "    return transcriptObject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581349e",
   "metadata": {},
   "source": [
    "## Action Oriented Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0e6951d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_videos_to_transcribe(channel_id,min_=0, max_=10000000000000):   \n",
    "    all_videos_for_channel_in_db =  get_all_videos_for_channel_from_db(channel_id)\n",
    "    videos_for_transcription = [x for x in all_videos_for_channel_in_db if (x['duration'] > min_) & (x['duration']<max_) ]\n",
    "    print(\"Videos to be transcribed: \",len(videos_for_transcription))\n",
    "    return videos_for_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a4f66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_transcription_batch( channelId, videos_for_transcription ): \n",
    "    model = whisper.load_model(\"base\").to(device)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "#     tee_to_file = TeeToFile(\"logs/transcription_logs/transcription_log_{}_{}.csv\".format(channelId, \n",
    "#                                                                                          datetime.datetime.now().timestamp()), \n",
    "#                             mode='a')\n",
    "    \n",
    "\n",
    "    for video in videos_for_transcription:\n",
    "        try:\n",
    "            print(\"Transcribing.... {} \".format(video['videoId']))\n",
    "            print(\"Duration {} {} \".format(video['videoId'],video['duration']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            whisper_transcription = transcribe_youtube_video(video['videoId'],\n",
    "                                                             \"https://www.youtube.com/watch?v={}\".format( video['videoId'] ),model)\n",
    "            transcription_json = transcription_response_to_json(whisper_transcription, video['videoId'], channelId)\n",
    "\n",
    "\n",
    "        except:\n",
    "            print(\"err {}\", video['videoId'])\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "#     tee_to_file.close()\n",
    "    warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63682fc5",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e0945f6-199a-4ce0-af87-5654759f755f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos to be transcribed:  19\n"
     ]
    }
   ],
   "source": [
    "channel_url = \"https://www.youtube.com/watch?v=lBCOOTyU46M&t=638s&ab_channel=ColinandSamir\"\n",
    "allChannels = get_all_channels_from_db()\n",
    "channel_id = video_url_to_channel_id(channel_url)\n",
    "\n",
    "\n",
    "videos_for_transcription = find_videos_to_transcribe(channel_id,min_=60*4,max_=60*5)\n",
    "json_string = json.dumps(videos_for_transcription)\n",
    "with open(\"videos_for_transcription.json\", \"w\") as file:\n",
    "    file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "680c1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_for_transcription_file = open(\"videos_for_transcription.json\", 'r')\n",
    "videos_for_transcription = json.loads(videos_for_transcription_file.read())\n",
    "videos_for_transcription = videos_for_transcription[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bdd89d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1086"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x['duration'] for x in videos_for_transcription[:4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3142202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df933fd",
   "metadata": {},
   "source": [
    "**Method 1:** Batched parallel processing\n",
    "\n",
    "Run transcriptions a few transcriptions in parallel at a time -- here i control for how many workers I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f166e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4, 2, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vids = len(videos_for_transcription)\n",
    "\n",
    "x_workers = 4\n",
    "a = math.ceil(num_vids/x_workers) #n_videos_per_thread\n",
    "\n",
    "x_workers_inputs = [\n",
    "        (channel_id,videos_for_transcription[i*a:(i+1)*a]) \n",
    "        for i in range(x_workers)\n",
    "]\n",
    "\n",
    "num_vids,x_workers,a, len(x_workers_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a039025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing.... sNGOgBcCcA4 \n",
      "Duration sNGOgBcCcA4 265 \n",
      "Transcribing.... _DRsu5Cv3O0 \n",
      "Duration _DRsu5Cv3O0 256 \n",
      "Transcribing.... K-hnbTqo6ko \n",
      "Duration K-hnbTqo6ko 253 \n",
      "Transcribing.... i05bI03nzv4 \n",
      "Duration i05bI03nzv4 261 \n",
      "Downloaded sNGOgBcCcA4\n",
      "Downloaded _DRsu5Cv3O0\n",
      "Downloaded K-hnbTqo6ko\n",
      "Downloaded i05bI03nzv4\n",
      "Transcribed K-hnbTqo6ko in 45.00648880004883\n",
      "Transcribing.... pwkOf7A6hkw \n",
      "Duration pwkOf7A6hkw 284 \n",
      "Downloaded pwkOf7A6hkw\n",
      "Transcribed sNGOgBcCcA4 in 51.32943296432495\n",
      "Transcribing.... re_osGoZf9w \n",
      "Duration re_osGoZf9w 280 \n",
      "Downloaded re_osGoZf9w\n",
      "Transcribed _DRsu5Cv3O0 in 54.23505210876465\n",
      "Transcribing.... vqp-87KaqTA \n",
      "Duration vqp-87KaqTA 284 \n",
      "Downloaded vqp-87KaqTA\n",
      "Transcribed i05bI03nzv4 in 55.9414222240448\n",
      "Transcribing.... TnyUCA-4BuQ \n",
      "Duration TnyUCA-4BuQ 280 \n",
      "Downloaded TnyUCA-4BuQ\n",
      "Transcribed re_osGoZf9w in 45.7160701751709\n",
      "Transcribed pwkOf7A6hkw in 56.11262917518616\n",
      "Transcribed TnyUCA-4BuQ in 50.43804311752319\n",
      "Transcribed vqp-87KaqTA in 52.681323766708374\n",
      "Total duration multiprocessing = 108.76661205291748\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=x_workers) as executor:\n",
    "    executor.map(run_transcription_batch, *zip(*x_workers_inputs))\n",
    "print(\"Total duration multiprocessing =\", time.time() - start)\n",
    "\n",
    "\n",
    "# tee_to_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32262152",
   "metadata": {},
   "source": [
    "**Method 2:** Full parallel processing \n",
    "\n",
    "Run transcriptions for all videos in parallel - here I control for how many videos I want grouped. I.e. 1 video groupings for all videos to run at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3bbd8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 1, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c =1\n",
    "y_workers = math.ceil(num_vids/ c)\n",
    "\n",
    "y_workers_inputs = [\n",
    "        (channel_id,videos_for_transcription[i*c:(i+1)*c]) \n",
    "        for i in range(y_workers)\n",
    "]\n",
    "\n",
    "num_vids,y_workers,c, len(y_workers_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d29f68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing.... sNGOgBcCcA4 \n",
      "Duration sNGOgBcCcA4 265 \n",
      "Transcribing.... TnyUCA-4BuQ \n",
      "Duration TnyUCA-4BuQ 280 \n",
      "Transcribing.... vqp-87KaqTA \n",
      "Duration vqp-87KaqTA 284 \n",
      "Transcribing.... _DRsu5Cv3O0 \n",
      "Duration _DRsu5Cv3O0 256 \n",
      "Transcribing.... pwkOf7A6hkw \n",
      "Duration pwkOf7A6hkw 284 \n",
      "Transcribing.... K-hnbTqo6ko \n",
      "Duration K-hnbTqo6ko 253 \n",
      "Transcribing.... re_osGoZf9w \n",
      "Duration re_osGoZf9w 280 \n",
      "Transcribing.... i05bI03nzv4 \n",
      "Duration i05bI03nzv4 261 \n",
      "Downloaded sNGOgBcCcA4\n",
      "Downloaded TnyUCA-4BuQ\n",
      "Downloaded vqp-87KaqTA\n",
      "Downloaded pwkOf7A6hkw\n",
      "Downloaded K-hnbTqo6ko\n",
      "Downloaded re_osGoZf9w\n",
      "Downloaded _DRsu5Cv3O0\n",
      "Downloaded i05bI03nzv4\n",
      "Transcribed K-hnbTqo6ko in 85.57955884933472\n",
      "Transcribed re_osGoZf9w in 96.60068821907043\n",
      "Transcribed sNGOgBcCcA4 in 100.4392101764679\n",
      "Transcribed TnyUCA-4BuQ in 107.00060796737671\n",
      "Transcribed i05bI03nzv4 in 108.68207597732544\n",
      "Transcribed _DRsu5Cv3O0 in 111.51289677619934\n",
      "Transcribed pwkOf7A6hkw in 112.63232612609863\n",
      "Transcribed vqp-87KaqTA in 112.72917890548706\n",
      "Total duration multiprocessing = 116.83316111564636\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=y_workers) as executor:\n",
    "    executor.map(run_transcription_batch, *zip(*y_workers_inputs))\n",
    "print(\"Total duration multiprocessing =\", time.time() - start)\n",
    "\n",
    "\n",
    "# tee_to_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ef7bb",
   "metadata": {},
   "source": [
    "**Method 3:** No parallel processing\n",
    "\n",
    "Run transcriptions sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "254f3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing.... i05bI03nzv4 \n",
      "Duration i05bI03nzv4 261 \n",
      "Downloaded i05bI03nzv4\n",
      "Transcribed i05bI03nzv4 in 24.353605270385742\n",
      "Transcribing.... TnyUCA-4BuQ \n",
      "Duration TnyUCA-4BuQ 280 \n",
      "Downloaded TnyUCA-4BuQ\n",
      "Transcribed TnyUCA-4BuQ in 25.48165988922119\n",
      "Transcribing.... sNGOgBcCcA4 \n",
      "Duration sNGOgBcCcA4 265 \n",
      "Downloaded sNGOgBcCcA4\n",
      "Transcribed sNGOgBcCcA4 in 24.232609033584595\n",
      "Transcribing.... re_osGoZf9w \n",
      "Duration re_osGoZf9w 280 \n",
      "Downloaded re_osGoZf9w\n",
      "Transcribed re_osGoZf9w in 20.613561868667603\n",
      "Transcribing.... K-hnbTqo6ko \n",
      "Duration K-hnbTqo6ko 253 \n",
      "Downloaded K-hnbTqo6ko\n",
      "Transcribed K-hnbTqo6ko in 18.787139177322388\n",
      "Transcribing.... pwkOf7A6hkw \n",
      "Duration pwkOf7A6hkw 284 \n",
      "Downloaded pwkOf7A6hkw\n",
      "Transcribed pwkOf7A6hkw in 29.11623501777649\n",
      "Transcribing.... _DRsu5Cv3O0 \n",
      "Duration _DRsu5Cv3O0 256 \n",
      "Downloaded _DRsu5Cv3O0\n",
      "Transcribed _DRsu5Cv3O0 in 31.737667083740234\n",
      "Transcribing.... vqp-87KaqTA \n",
      "Duration vqp-87KaqTA 284 \n",
      "Downloaded vqp-87KaqTA\n",
      "Transcribed vqp-87KaqTA in 36.827014207839966\n",
      "duration = 211.71395778656006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "run_transcription_batch(channel_id,videos_for_transcription)\n",
    "\n",
    "print(\"duration =\", time.time() - start)\n",
    "\n",
    "# tee_to_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2757ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_1_time= 108.8\n",
    "method_2_time= 116.8\n",
    "method_3_time= 211.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61a82207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Comparing...Method 1   Method 2   Method 3\n",
      "\n",
      "To:\n",
      "Method 1:...............0.9.........0.5\n",
      "\n",
      "Method 2:....1.1....................0.6\n",
      "\n",
      "Method 3:....1.9..........1.0...........\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "\n",
    "Comparing...Method 1   Method 2   Method 3\n",
    "\n",
    "To:\n",
    "Method 1:...............{}.........{}\n",
    "\n",
    "Method 2:....{}....................{}\n",
    "\n",
    "Method 3:....{}..........{}...........\n",
    "\n",
    "\"\"\".format(round(method_1_time/method_2_time,1),\n",
    "          round(method_1_time/method_3_time,1),\n",
    "          round(method_2_time/method_1_time,1),\n",
    "          round(method_2_time/method_3_time,1),\n",
    "          round(method_3_time/method_1_time,1),\n",
    "          round(method_3_time/method_3_time,1))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ceea2",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dd1eba",
   "metadata": {},
   "source": [
    "- Multi threading improved speed by about to 50%\n",
    "- 10% difference between batch processing and full parallel processing with batch being better\n",
    "- if batch and full parallel were equal i would still go with batch because there is more risk waiting 1 full hour for results (if something crashes halfway then there will be 0 results availabe) as opposed to getting results every few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65345f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51826b13-6ed0-478e-be47-cbd7a30b39e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install openai-whisper\n",
    "# !pip install firebase-admin\n",
    "# !pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ebecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#terminal - python show ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54055a8-4452-4440-895f-cf0f01569d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kitanademidun/anaconda3/envs/wordtoobe/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import urllib.parse as p\n",
    "import subprocess\n",
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "import youtube_dl\n",
    "from pytube import YouTube  # !pip install pytube\n",
    "from pytube.exceptions import RegexMatchError\n",
    "from tqdm.auto import tqdm  # !pip install tqdm\n",
    "# from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3846224",
   "metadata": {},
   "source": [
    "#### whisper model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a211e4-0f71-483c-8f4c-312763cfb81e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 20:24:54,157\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/Users/kitanademidun/anaconda3/envs/wordtoobe/lib/python3.11/site-packages/whisper/timing.py:57: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit\n"
     ]
    }
   ],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import ray\n",
    "import whisper\n",
    "import torch\n",
    "audio_file= open(\"audio_file.mp3\", \"rb\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = whisper.load_model(\"base\").to(device)\n",
    "# result = model.transcribe('audio_file.mp3')\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3b1cd",
   "metadata": {},
   "source": [
    "#### google client set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31a1644-d2cf-46e3-a321-48372c281596",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = os.getenv('GOOGLE_DEVELOPER_KEY')\n",
    "\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey = DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4080e0",
   "metadata": {},
   "source": [
    "#### firebase set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7967c5d2-bb92-4004-901e-410e248f0f6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "# Use a service account.\n",
    "cred = credentials.Certificate('{}.json'.format(os.getenv('PROJECT_ID')))\n",
    "\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "db = firestore.client(app)\n",
    "batch = db.batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217213e",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69d587",
   "metadata": {},
   "source": [
    "#### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bf5f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TeeToFile:\n",
    "    \"\"\"\n",
    "    In the code , the TeeToFile class is designed to mimic the behavior of the tee command in Unix-like systems. It captures the output and sends it both to the original sys.stdout (the console) and to a specified file. You can instantiate this class with the desired filename and mode (e.g., 'w' for write, 'a' for append).\n",
    "\n",
    "    Once you run this code, any text printed using the print function will be displayed in the notebook and simultaneously saved to the specified file. The TeeToFile instance must be closed using the close method when you're done with it to properly restore the original sys.stdout and close the file.\n",
    "\n",
    "    Remember that using this approach can lead to some issues, particularly in more complex scenarios. If you encounter unexpected behavior, you might want to consider using a logging library like logging for better control and flexibility.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename, mode='w'):\n",
    "        self.file = open(filename, mode)\n",
    "        self.stdout = sys.stdout\n",
    "        sys.stdout = self\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "    def write(self, data):\n",
    "        self.stdout.write(data)\n",
    "        self.file.write(data)\n",
    "\n",
    "    def flush(self):\n",
    "        self.stdout.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        if self.file:\n",
    "            sys.stdout = self.stdout\n",
    "            self.file.close()\n",
    "            self.file = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab419409",
   "metadata": {},
   "source": [
    "#### functions calling to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5882bc6-1b5d-4a2a-a9d2-7bb3c919947d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_channels_from_db():\n",
    "    \"\"\"\n",
    "    Retrieve list of channels from firebase\n",
    "    \"\"\"\n",
    "    docs = db.collection(u'channels').stream()\n",
    "    channelsCollection = {}\n",
    "    for doc in docs:\n",
    "        channelsCollection[doc.id]=doc.to_dict()\n",
    "    return channelsCollection\n",
    "\n",
    "def get_all_videos_for_channel_from_db(channelId):\n",
    "    \"\"\"\n",
    "    Retrieve list of videos from firebase\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.collection(u\"videos\").order_by('publishedAt', direction=firestore.Query.DESCENDING).where(u\"channelId\",u\"==\",u\"{}\".format(channelId)).stream()\n",
    "\n",
    "    collection = []\n",
    "    for doc in docs:\n",
    "        vid =doc.to_dict()\n",
    "        collection.append(vid)\n",
    "    return collection\n",
    "\n",
    "def get_all_transcripts_for_channel_from_db(channelId):\n",
    "    \"\"\"\n",
    "    Retrieve list of videos from firebase\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.collection(u\"WhisperTranscriptions\").where(u\"channelId\",u\"==\",u\"{}\".format(channelId)).stream()\n",
    "\n",
    "    collection = []\n",
    "    for doc in docs:\n",
    "        transcript =doc.to_dict()\n",
    "        collection.append(transcript)\n",
    "        \n",
    "    return collection\n",
    "\n",
    "def get_channel_doc(channel_id,allChannels):\n",
    "    #channel_id = video_url_to_channel_id(video_url)\n",
    "\n",
    "    for record in allChannels.values():\n",
    "        \n",
    "        if record['channelId'] == channel_id:\n",
    "            print(\"Channel {} already exists.\".format(record['title']))\n",
    "            return record\n",
    "\n",
    "    channelToAdd = generate_channel_json(video_url, source=\"id\")\n",
    "\n",
    "\n",
    "    add = input(\"Create channel for url ? (0 for no, any other key for yes)\".format(channelToAdd['title']))\n",
    "\n",
    "    if add == \"0\":\n",
    "        print(\"No channel for url\")\n",
    "        return\n",
    "\n",
    "\n",
    "    docRef = db.collection(u\"channels\").document(u\"{}\".format(channelToAdd['channelId'])).set(channelToAdd)\n",
    "    print(\"Channel {} is created.\".format(channelToAdd['title']))\n",
    "    return channelToAdd\n",
    "\n",
    "def add_video_to_db(video):\n",
    "    docRef = db.collection(u\"videos\").document(u\"{}\".format(video['videoId']))\n",
    "    docRef.set(video)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52828f",
   "metadata": {},
   "source": [
    "#### function for pulling youtube data from apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31dea409-f1ee-4c61-b9df-436f545998a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def video_url_to_channel_id(video_url):\n",
    "    \"\"\"\n",
    "    Take a url for a youtube video and get the channel id\n",
    "    \"\"\"\n",
    "    video_param_from_url = video_url.split(\"/watch?v=\")[1].split(\"&\")[0]\n",
    "    request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=video_param_from_url\n",
    "        )\n",
    "    response = request.execute()\n",
    "    channel_id = response['items'][0]['snippet']['channelId']\n",
    "    return channel_id\n",
    "\n",
    "def get_uploads_id(youtube, channel_id):\n",
    "    request = youtube.channels().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "    response = request.execute()\n",
    "    return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "\n",
    "def get_uploaded_videos_response(youtube, channel_id):\n",
    "\n",
    "    ## define parameters needed\n",
    "    playlist_id = get_uploads_id(youtube, channel_id) #Plalylist id will get ut the id that returns the full video list\n",
    "\n",
    "    params = {\n",
    "        \"part\":\"snippet,contentDetails\",\n",
    "        \"playlistId\": playlist_id,\n",
    "        \"maxResults\": 50\n",
    "    }\n",
    "\n",
    "\n",
    "    uploaded_videos_content_details_list = []\n",
    "\n",
    "    while True:\n",
    "        response = youtube.playlistItems().list(**params).execute()\n",
    "\n",
    "        uploaded_videos_content_details_list = uploaded_videos_content_details_list + response.get('items')\n",
    "        if 'nextPageToken' in response.keys():\n",
    "            params['pageToken'] = response['nextPageToken']\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(\"{} videos retreived.\".format(len(uploaded_videos_content_details_list)))\n",
    "    return uploaded_videos_content_details_list\n",
    "\n",
    "def filter_uploaded_videos_response(youtube, uploaded_videos_response,**args):\n",
    "    \n",
    "    max_total=args.get(\"max_total\") if args.get(\"max_total\") else False #max_total will allow us to define the number of videos we want returned\n",
    "    oldest_date=args.get(\"oldest_date\") if args.get(\"oldest_date\") else False #if a value is provided, only get videos on or after this date\n",
    "\n",
    "    if oldest_date:\n",
    "        recent_uploaded_videos_response = list(filter(lambda x:x['snippet']['publishedAt'].split(\"T\")[0] >= '2023-06-30',uploaded_videos_response))\n",
    "        if max_total:\n",
    "            return recent_uploaded_videos_response[:max_total]\n",
    "    elif max_total:\n",
    "        return uploaded_videos_response[:max_total]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce27d0",
   "metadata": {},
   "source": [
    "#### functions for getting data into the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44462e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "def video_response_to_dict(x):\n",
    "\n",
    "    video_df = {}\n",
    "    video_df['id'] = x['id']\n",
    "    video_df['videoId'] = x['contentDetails']['videoId']\n",
    "    video_df['title'] = x['snippet']['title']\n",
    "    video_df['description'] = x['snippet']['description']\n",
    "    video_df['thumbnail'] = check_nested_dict_keys(x,[\"snippet\",\"thumbnails\",\"maxres\",\"url\"])\n",
    "    video_df['channelId'] = x['snippet']['channelId']\n",
    "    video_df['videoId'] = x['contentDetails']['videoId']\n",
    "    video_df['publishedAt'] =x['snippet']['publishedAt'].split(\"T\")[0]\n",
    "    video_df['videoUrl'] = \"https://www.youtube.com/watch?v={}\".format(x['contentDetails']['videoId'] )\n",
    "    video_df['duration'] = getYoutubeDuration(x['contentDetails']['videoId']  )\n",
    "    video_df['transcript_status'] = None\n",
    "    video_df['text'] = ''\n",
    "\n",
    "    return video_df      \n",
    "  \n",
    "    \n",
    "def video_response_list_to_list_of_dicts(response_list):\n",
    "\n",
    "    list_of_dicts = []\n",
    "    for x in response_list:\n",
    "        if \"#shorts\" in x['snippet']['title'].lower():\n",
    "            continue\n",
    "\n",
    "        video_df = video_response_to_dict(video_response(x))\n",
    "        list_of_dicts.append(video_df)\n",
    "\n",
    "\n",
    "    return list_of_dicts      \n",
    "\n",
    "def generate_channel_json(sourceValue, source=\"url\"):\n",
    "\n",
    "    if source==\"id\":\n",
    "        channel_id = sourceValue\n",
    "    elif source==\"url\":\n",
    "        video_url = sourceValue\n",
    "        channel_id = video_url_to_channel_id(video_url)\n",
    "    else:\n",
    "        raise Exception(\"{} not a valid source.\".format(source))\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "    \n",
    "    response = request.execute()\n",
    "\n",
    "    channel_df = {}\n",
    "    channel_df['channelId'] = channel_id\n",
    "    channel_df['title'] = response['items'][0]['snippet']['title']\n",
    "    channel_df['uploads'] = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    channel_df['description'] = response['items'][0]['snippet']['description']\n",
    "    channel_df['thumbnail'] = check_nested_dict_keys(response['items'][0],[\"snippet\",\"thumbnails\",\"high\",\"url\"])\n",
    "    channel_df['videos'] = []\n",
    "\n",
    "    return channel_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce4668",
   "metadata": {},
   "source": [
    "#### functions for extracting details from response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beff51e9-775a-477b-9c7f-8c40c263ddc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getYoutubeDuration(videoId):\n",
    "    responseVideoDetails = youtube.videos().list( part=\"contentDetails\",id=videoId).execute()\n",
    "    durationResponse=responseVideoDetails['items'][0]['contentDetails']['duration']\n",
    "\n",
    "    duration_string = durationResponse.replace('PT',\"\")\n",
    "    number_values = re.findall('\\d+',duration_string)\n",
    "    symbols_available= ''.join([i for i in duration_string if not i.isdigit()])\n",
    "    symbol_map = {}\n",
    "    for symbol in 'HMS':\n",
    "        index = symbols_available.find(symbol)\n",
    "        if index > -1:\n",
    "            symbol_map[symbol] = number_values[index]\n",
    "\n",
    "    duration = 0\n",
    "\n",
    "\n",
    "    for idx in symbol_map:\n",
    "        if idx == \"H\":\n",
    "            duration = int(symbol_map[idx])*60*60 + duration\n",
    "        if idx == \"M\":\n",
    "            duration = int(symbol_map[idx])*60 + duration\n",
    "        if idx == \"S\":\n",
    "            duration = int(symbol_map[idx]) + duration\n",
    "\n",
    "    return duration\n",
    "\n",
    "def check_nested_dict_keys(dic, keys):\n",
    "    d = dic\n",
    "    for key in keys:\n",
    "        if key in d.keys():\n",
    "            d = d[key]\n",
    "            continue\n",
    "        else:\n",
    "            return dic['snippet']['thumbnails']['default']['url']\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0bafc",
   "metadata": {},
   "source": [
    "#### transcription functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3fd2cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_audio(url,_id):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        out_file=video.download(output_path=\"audio_files\")\n",
    "        base, ext = os.path.splitext(out_file)\n",
    "        new_file = 'audio_files/'+_id+'.mp3'\n",
    "        os.rename(out_file, new_file)\n",
    "        a = new_file\n",
    "    except Exception as e: # work on python 3.x\n",
    "        print('Could not download data for {}: '.format(_id),e)\n",
    "        return None\n",
    "    return a\n",
    "\n",
    "def transcribe_youtube_video(videoId, videoUrl,model):\n",
    "\n",
    "    result = {}\n",
    "\n",
    "# try:\n",
    "    start_time = time.time()\n",
    "\n",
    "    audio_downloaded = get_audio(videoUrl,videoId)\n",
    "    if not audio_downloaded:\n",
    "        print('Could not get transcription data {} Audio could not download.'.format(videoId))\n",
    "        return\n",
    "\n",
    "    print('Downloaded {}'.format(videoId))\n",
    "\n",
    "    # transcribe to get speech-to-text data\n",
    "    result = model.transcribe('audio_files/{}.mp3'.format(videoId))\n",
    "    os.remove(\"audio_files/{}.mp3\".format(videoId))\n",
    "    source = \"whisper\"\n",
    "    time_to_transcbribe = time.time() - start_time\n",
    "    print('Transcribed {} in {}'.format(videoId,time_to_transcbribe))\n",
    "\n",
    "#     except Exception as e: # work on python 3.x\n",
    "#         print('Could not get transcription data {}.'.format(videoId),e)\n",
    "\n",
    "    return result\n",
    "\n",
    "def transcription_response_to_json(transcriptResponse, videoId, channelId):\n",
    "    transcriptObject = {}\n",
    "    transcriptObject['videoId'] = videoId\n",
    "    transcriptObject['channelId'] = channelId\n",
    "\n",
    "    transcriptObject['text'] = transcriptResponse['text']\n",
    "    segments = transcriptResponse['segments']\n",
    "    keys = ['start','end','text','id','seek']\n",
    "    transcriptObject['sentences'] = [{ keep: item[keep] for keep in keys } for item,i in zip(segments,range(len(segments)) )]\n",
    "    \n",
    "    return transcriptObject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581349e",
   "metadata": {},
   "source": [
    "## Action Oriented Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84dd2a45-18ea-45fd-903a-14b16a1a6c03",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_video_db_for_channel(channel_id):\n",
    "    all_videos_for_channel_in_db = get_all_videos_for_channel_from_db(channel_id)\n",
    "    uploaded_videos_response = get_uploaded_videos_response(youtube, channel_id)\n",
    "    cleaned_video_response = [video_response_to_dict(x) for x in uploaded_videos_response]\n",
    "\n",
    "    video_ids_in_db = [x['videoId'] for x in all_videos_for_channel_in_db ]\n",
    "    videos_not_in_db = list(filter(lambda x:x['videoId'] not in video_ids_in_db, cleaned_video_response))\n",
    "    \n",
    "    print(\"New videos: \",len(videos_not_in_db))\n",
    "\n",
    "    for video in videos_not_in_db:    \n",
    "        add_video_to_db(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e6951d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_videos_to_transcribe(channel_id):   \n",
    "    all_videos_for_channel_in_db =  get_all_videos_for_channel_from_db(channel_id)\n",
    "    transcripts_for_channel_from_db = get_all_transcripts_for_channel_from_db(channel_id)\n",
    "    transcript_ids_in_db = [x['videoId'] for x in transcripts_for_channel_from_db ]\n",
    "    videos_wo_transcript = list(filter(lambda x:x['videoId'] not in transcript_ids_in_db, all_videos_for_channel_in_db))\n",
    "    videos_for_transcription = [x for x in videos_wo_transcript if (x['duration'] > 60*5) & (x['duration']<60*45) ]\n",
    "    print(\"Videos to be transcribed: \",len(videos_for_transcription))\n",
    "    return videos_for_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a4f66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_transcription_batch( channelId, videos_for_transcription ): \n",
    "    model = whisper.load_model(\"base\").to(device)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "#     tee_to_file = TeeToFile(\"logs/transcription_logs/transcription_log_{}_{}.csv\".format(channelId, \n",
    "#                                                                                          datetime.datetime.now().timestamp()), \n",
    "#                             mode='a')\n",
    "    \n",
    "\n",
    "    for video in videos_for_transcription:\n",
    "        try:\n",
    "            print(\"Transcribing.... {} \".format(video['videoId']))\n",
    "            print(\"Duration {} {} \".format(video['videoId'],video['duration']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            whisper_transcription = transcribe_youtube_video(video['videoId'],\n",
    "                                                             \"https://www.youtube.com/watch?v={}\".format( video['videoId'] ),model)\n",
    "\n",
    "            transcription_json = transcription_response_to_json(whisper_transcription, video['videoId'], channelId)\n",
    "\n",
    "            docRef = db.collection(u\"WhisperTranscriptions\").document(u\"{}\".format(video['videoId']))\n",
    "            docRef.set( transcription_json)\n",
    "            videoRef = db.collection(u\"videos\").document(video['videoId']).update({\"transcript_status\": True,'text':transcription_json['text']})\n",
    "\n",
    "            print(\"Transcription added: {}\".format(video['videoId']))\n",
    "\n",
    "        except:\n",
    "            print(\"err {}\", video['videoId'])\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "#     tee_to_file.close()\n",
    "    warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63682fc5",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e0945f6-199a-4ce0-af87-5654759f755f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_url = \"https://www.youtube.com/watch?v=lBCOOTyU46M&t=638s&ab_channel=ColinandSamir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb2e15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allChannels = get_all_channels_from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2b5f8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Colin and Samir already exists.\n"
     ]
    }
   ],
   "source": [
    "channel_id = video_url_to_channel_id(channel_url)\n",
    "channel = get_channel_doc(channel_id,allChannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80c805ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos_for_channel_in_db =  get_all_videos_for_channel_from_db(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79518b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 videos retreived.\n",
      "New videos:  0\n"
     ]
    }
   ],
   "source": [
    "update_video_db_for_channel(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "589a0b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos to be transcribed:  50\n"
     ]
    }
   ],
   "source": [
    "videos_for_transcription = find_videos_to_transcribe(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c637eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j=4\n",
    "l = [(channel_id,videos_for_transcription[i*j:(i+1)*j]) for i in range(math.ceil(len(videos_for_transcription)/j))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b006db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing.... 3QZkjsMfj3I \n",
      "Duration 3QZkjsMfj3I 1207 \n",
      "Transcribing.... 88067BiKU4Y \n",
      "Duration 88067BiKU4Y 1374 \n",
      "Transcribing.... VbNIh88Nq5k \n",
      "Duration VbNIh88Nq5k 2449 \n",
      "Transcribing.... fyh2-2qXSLI \n",
      "Duration fyh2-2qXSLI 1313 \n",
      "Downloaded 3QZkjsMfj3I\n",
      "Downloaded fyh2-2qXSLI\n",
      "Downloaded VbNIh88Nq5k\n",
      "Downloaded 88067BiKU4Y\n",
      "Transcribed 3QZkjsMfj3I in 202.0113627910614\n",
      "Transcription added: 3QZkjsMfj3I\n",
      "Transcribing.... cbBxEmGOfk4 \n",
      "Duration cbBxEmGOfk4 1396 \n",
      "Could not download data for cbBxEmGOfk4:  cbBxEmGOfk4 is age restricted, and can't be accessed without logging in.\n",
      "Could not get transcription data cbBxEmGOfk4 Audio could not download.\n",
      "err {} cbBxEmGOfk4\n",
      "Transcribing.... gGBCbswZbnI \n",
      "Duration gGBCbswZbnI 1856 \n",
      "Downloaded gGBCbswZbnI\n",
      "Transcribed fyh2-2qXSLI in 278.0321719646454\n",
      "Transcription added: fyh2-2qXSLI\n",
      "Transcribing.... gbDunxRfbgg \n",
      "Duration gbDunxRfbgg 1390 \n",
      "Downloaded gbDunxRfbgg\n",
      "Transcribed 88067BiKU4Y in 298.7525990009308\n",
      "Transcription added: 88067BiKU4Y\n",
      "Transcribing.... jzMsnNxzejI \n",
      "Duration jzMsnNxzejI 1620 \n",
      "Downloaded jzMsnNxzejI\n",
      "Transcribed VbNIh88Nq5k in 451.9889130592346\n",
      "Transcription added: VbNIh88Nq5k\n",
      "Transcribing.... XuVR_elE1Pw \n",
      "Duration XuVR_elE1Pw 1277 \n",
      "Downloaded XuVR_elE1Pw\n",
      "Transcribed gbDunxRfbgg in 243.9546389579773\n",
      "Transcription added: gbDunxRfbgg\n",
      "Transcribing.... 7zd6EA5GdEM \n",
      "Duration 7zd6EA5GdEM 1468 \n",
      "Downloaded 7zd6EA5GdEM\n",
      "Transcribed gGBCbswZbnI in 398.88463592529297\n",
      "Transcription added: gGBCbswZbnI\n",
      "Transcribing.... hYaGD0V2OkE \n",
      "Duration hYaGD0V2OkE 1208 \n",
      "Downloaded hYaGD0V2OkE\n",
      "Transcribed jzMsnNxzejI in 330.38714504241943\n",
      "Transcription added: jzMsnNxzejI\n",
      "Transcribing.... pvtMJFPyiLM \n",
      "Duration pvtMJFPyiLM 1230 \n",
      "Downloaded pvtMJFPyiLM\n",
      "Transcribed XuVR_elE1Pw in 277.19660806655884\n",
      "Transcription added: XuVR_elE1Pw\n",
      "Transcribing.... r8bzWKBvZsE \n",
      "Duration r8bzWKBvZsE 1595 \n",
      "Downloaded r8bzWKBvZsE\n",
      "Transcribed hYaGD0V2OkE in 232.67734622955322\n",
      "Transcription added: hYaGD0V2OkE\n",
      "Transcribing.... x5lBJE2Ok8E \n",
      "Duration x5lBJE2Ok8E 1361 \n",
      "Downloaded x5lBJE2Ok8E\n",
      "Transcribed pvtMJFPyiLM in 222.5644588470459\n",
      "Transcription added: pvtMJFPyiLM\n",
      "Transcribing.... 7hrSj5qkHv4 \n",
      "Duration 7hrSj5qkHv4 1571 \n",
      "Downloaded 7hrSj5qkHv4\n",
      "Transcribed 7zd6EA5GdEM in 377.3901159763336\n",
      "Transcription added: 7zd6EA5GdEM\n",
      "Transcribing.... IjoTYJNr8DA \n",
      "Duration IjoTYJNr8DA 2292 \n",
      "Downloaded IjoTYJNr8DA\n",
      "Transcribed r8bzWKBvZsE in 345.40462017059326\n",
      "Transcription added: r8bzWKBvZsE\n",
      "Transcribing.... 9CxaZWkwHzE \n",
      "Duration 9CxaZWkwHzE 1852 \n",
      "Downloaded 9CxaZWkwHzE\n",
      "Transcribed x5lBJE2Ok8E in 290.90770387649536\n",
      "Transcription added: x5lBJE2Ok8E\n",
      "Transcribing.... G5c6qof96DM \n",
      "Duration G5c6qof96DM 1306 \n",
      "Downloaded G5c6qof96DM\n",
      "Transcribed 7hrSj5qkHv4 in 349.6828281879425\n",
      "Transcription added: 7hrSj5qkHv4\n",
      "Transcribing.... PiGCHXt5eBs \n",
      "Duration PiGCHXt5eBs 1856 \n",
      "Downloaded PiGCHXt5eBs\n",
      "Transcribed 9CxaZWkwHzE in 328.42396688461304\n",
      "Transcription added: 9CxaZWkwHzE\n",
      "Transcribing.... ZlR0Rsu_VeU \n",
      "Duration ZlR0Rsu_VeU 1235 \n",
      "Downloaded ZlR0Rsu_VeU\n",
      "Transcribed G5c6qof96DM in 300.3354642391205\n",
      "Transcription added: G5c6qof96DM\n",
      "Transcribing.... dbOXYhjpXAc \n",
      "Duration dbOXYhjpXAc 1210 \n",
      "Downloaded dbOXYhjpXAc\n",
      "Transcribed PiGCHXt5eBs in 350.6363310813904\n",
      "Transcription added: PiGCHXt5eBs\n",
      "Transcribing.... BVEzAyZXctY \n",
      "Duration BVEzAyZXctY 1459 \n",
      "Downloaded BVEzAyZXctY\n",
      "Transcribed ZlR0Rsu_VeU in 242.73269081115723\n",
      "Transcription added: ZlR0Rsu_VeU\n",
      "Transcribing.... TAFYbWgX8K0 \n",
      "Duration TAFYbWgX8K0 1400 \n",
      "Downloaded TAFYbWgX8K0\n",
      "Transcribed dbOXYhjpXAc in 242.53936290740967\n",
      "Transcription added: dbOXYhjpXAc\n",
      "Transcribing.... YVuIm8OLz-8 \n",
      "Duration YVuIm8OLz-8 1508 \n",
      "Downloaded YVuIm8OLz-8\n",
      "Transcribed IjoTYJNr8DA in 798.2663140296936\n",
      "Transcription added: IjoTYJNr8DA\n",
      "Transcribing.... WVI2GUdJp2Y \n",
      "Duration WVI2GUdJp2Y 2207 \n",
      "Downloaded WVI2GUdJp2Y\n",
      "Transcribed BVEzAyZXctY in 309.65908098220825\n",
      "Transcription added: BVEzAyZXctY\n",
      "Transcribing.... nxyThD3-GTw \n",
      "Duration nxyThD3-GTw 2294 \n",
      "Downloaded nxyThD3-GTw\n",
      "Transcribed TAFYbWgX8K0 in 288.842542886734\n",
      "Transcription added: TAFYbWgX8K0\n",
      "Transcribing.... lQyAdgLwbLk \n",
      "Duration lQyAdgLwbLk 2463 \n",
      "Downloaded lQyAdgLwbLk\n",
      "Transcribed YVuIm8OLz-8 in 323.36939811706543\n",
      "Transcription added: YVuIm8OLz-8\n",
      "Transcribing.... lBGq8vWx7B0 \n",
      "Duration lBGq8vWx7B0 1660 \n",
      "Could not download data for lBGq8vWx7B0:  lBGq8vWx7B0 is age restricted, and can't be accessed without logging in.\n",
      "Could not get transcription data lBGq8vWx7B0 Audio could not download.\n",
      "err {} lBGq8vWx7B0\n",
      "Transcribing.... lGmrpX7KkcU \n",
      "Duration lGmrpX7KkcU 1530 \n",
      "Downloaded lGmrpX7KkcU\n",
      "Transcribed WVI2GUdJp2Y in 412.7396070957184\n",
      "Transcription added: WVI2GUdJp2Y\n",
      "Transcribing.... 9w0kTRvOQWA \n",
      "Duration 9w0kTRvOQWA 1668 \n",
      "Downloaded 9w0kTRvOQWA\n",
      "Transcribed lGmrpX7KkcU in 336.4186038970947\n",
      "Transcription added: lGmrpX7KkcU\n",
      "Transcribing.... pVhrApLIraI \n",
      "Duration pVhrApLIraI 1480 \n",
      "Downloaded pVhrApLIraI\n",
      "Transcribed nxyThD3-GTw in 579.1770551204681\n",
      "Transcription added: nxyThD3-GTw\n",
      "Transcribing.... O0C417mFrRQ \n",
      "Duration O0C417mFrRQ 2255 \n",
      "Downloaded O0C417mFrRQ\n",
      "Transcribed 9w0kTRvOQWA in 381.40753722190857\n",
      "Transcription added: 9w0kTRvOQWA\n",
      "Transcribing.... j7eETkQcHLA \n",
      "Duration j7eETkQcHLA 1565 \n",
      "Downloaded j7eETkQcHLA\n",
      "Transcribed lQyAdgLwbLk in 576.272087097168\n",
      "Transcription added: lQyAdgLwbLk\n",
      "Transcribing.... HGhT5GMhf8A \n",
      "Duration HGhT5GMhf8A 1732 \n",
      "Downloaded HGhT5GMhf8A\n",
      "Transcribed pVhrApLIraI in 475.38215613365173\n",
      "Transcription added: pVhrApLIraI\n",
      "Transcribing.... Fz27v1gnCFM \n",
      "Duration Fz27v1gnCFM 1449 \n",
      "Downloaded Fz27v1gnCFM\n",
      "Transcribed j7eETkQcHLA in 856.0219526290894\n",
      "Transcription added: j7eETkQcHLA\n",
      "Transcribing.... 5EfQqwDmOnI \n",
      "Duration 5EfQqwDmOnI 1553 \n",
      "Downloaded 5EfQqwDmOnI\n",
      "Transcribed HGhT5GMhf8A in 901.9646589756012\n",
      "Transcription added: HGhT5GMhf8A\n",
      "Transcribing.... BSXMM9Y1blk \n",
      "Duration BSXMM9Y1blk 1648 \n",
      "Downloaded BSXMM9Y1blk\n",
      "Transcribed O0C417mFrRQ in 1044.8160738945007\n",
      "Transcription added: O0C417mFrRQ\n",
      "Transcribing.... knl2UOFr8bk \n",
      "Duration knl2UOFr8bk 1409 \n",
      "Downloaded knl2UOFr8bk\n",
      "Transcribed Fz27v1gnCFM in 960.2341351509094\n",
      "Transcription added: Fz27v1gnCFM\n",
      "Transcribing.... Ptk6P7Lc6rs \n",
      "Duration Ptk6P7Lc6rs 1459 \n",
      "Downloaded Ptk6P7Lc6rs\n",
      "Transcribed 5EfQqwDmOnI in 627.2829911708832\n",
      "Transcription added: 5EfQqwDmOnI\n",
      "Transcribing.... jNGUBzKadtw \n",
      "Duration jNGUBzKadtw 1203 \n",
      "Downloaded jNGUBzKadtw\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def your_function(param1, param2):\n",
    "    # Your function's code here\n",
    "    result = param1 + param2\n",
    "    return result\n",
    "\n",
    "param_sets = l#[(1, 2), (3, 4), (5, 6), (7, 8)]  # Example parameter sets\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(run_transcription_batch, *zip(*param_sets))\n",
    "print(\"duration =\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f346fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
